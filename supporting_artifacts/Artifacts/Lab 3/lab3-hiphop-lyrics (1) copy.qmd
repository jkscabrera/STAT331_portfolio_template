

---
title: "Lab 3 Revision"
author: "Jasmine Cabrera"
format:
  html:
    self-contained: true
    code-tools: true 
    code-fold: true
execute:
  echo: true
  error: false
  messages: false
  warning: false
---

The downloaded file **does not** contain an YAML, you need to include your own. This allows you to specify how you would like your rendered HTML to look! The sky is the limit!
:::

[Download `hiphop.csv`](hiphop.csv)

::: callout-warning
Save **both** your .qmd file and your data set in the same folder within your Stat 331 directory! **DO NOT** open your .qmd file straight from your downloads folder.
:::

## Tips for Formatting your Lab

::: {.callout-tip collapse="true"}
-   The first chunk of your Quarto document should be to *declare your libraries* (probably only `tidyverse` for now).
-   The second chunk of your Quarto document should be to *load in your data* (using the `here()` function!).
-   Make sure you address **all the questions** in these instructions.
-   If a question requires **any** type of calculation, **you should provide code for your answer!**
-   I have provided hints about functions that might be useful to you. You are **not required** to use these functions.
-   You may have to Google to solve some of these!
-   Be sure to **save** your work regularly (`Ctrl/Cmd + S` or `File > Save` or the floppy disk icon)
-   Be sure to **render** your file every so often, to check for errors and make sure it looks nice.
    -   Make your Quarto document does not contain `View(dataset)` or `install.packages("package")`, both of these will prevent rendering.
    -   Check your Quarto document for moments when you looked at the data by typing the name of the data frame. Leaving these in means the whole dataset will print out and this looks unprofessional.
    -   If you are unable to finish due to errors in your code, remember that you can still submit an HTML file if you specify `error: true` in your `execute` options (in the YAML).
:::

# Data Set

The data set `hiphop` contains results from a study conducted by a linguist at the University of Minnesota. The researcher was interested in predicting musical taste based on familiarity with African American English (AAE). 168 subjects participated in the study, and each was asked to define 64 different AAE terms. The definitions given were used to create a `familiarity` score for each subject for each term. This score quantifies how well the subject knew the term on a scale of 1-5 (1 = not at all, 5 = very well). Before tackling the problems, study the description of each variable [here](http://conservancy.umn.edu/bitstream/handle/11299/116327/5/explanationAAEHiphopChesley.txt).

**1. Load the appropriate R packages and import the data set, `hiphop`.**

```{r packages}
# code chunk for loading packages and importing the data
#| message: false

# Loads in packages
library(tidyverse)
library(here)

# Imports data
hiphop <- read_csv(here("hiphop.csv"))
```
Q1 Fix - Considered S:
Fixed error message by specifying error: false in YAML.

## Summary

**2. Provide a brief overview (2-4 sentences) of the data set.**

```{r dataset-explore}
# you may want to use code to answer this question

# Outputs dimensions of data set
dim(hiphop)

# Outputs data types of data set
str(hiphop)

```

Q2 Answer: 
From the output "10752 38", we know that the hip hop data set has 10,752 rows 
and 38 columns. Out of the 38 variables, there are 4 character variables and 34 
numeric variables.

Q2 Fix:
Placing Answers to questions in report section and not in comment section.

**3. What are the rows of this data set?**

```{r rows}
# you may want to use code to answer this question

# https://conservancy.umn.edu/bitstream/handle/11299/116327/5/explanationAAEHiphopChesley.txt
# Gets frequency of each "word"
hiphop |>
  count(word)
```

Q3 Answer:
After reading the description provided by the researcher, I believe that each row 
is designed to represent one word being tested. The code supports this theory 
since there are 168 participants and 64 words as stated in the document. Therefore, 
the count function should create a 64 x 2 tibble containing 64 words each with a 
frequency of 168 (one for each participant).

Q3 Fix:
Placing Answers to questions in report section and not in comment section.

## Cleaning the Data

**4. Missing values for some of the variables were replaced with other values. How were missing values replaced? What do you believe are some benefits and drawbacks of doing this?**

```{r missing}
# you may want to use code to answer this question

# https://conservancy.umn.edu/bitstream/handle/11299/116327/5/explanationAAEHiphopChesley.txt
```

Q4 Answer: 
As stated in the research document, the missing values were replaced with mean values in the social network variables (i.e. blackWeekly). The benefits of doing so are that the data would no longer have NA values and calculations can easily be computed without the worry of receiving an error. The drawbacks, however, are that these mean values are not from the raw data, and thus, these values can skew and change the results of computation.

Q4 Fix:
Placing Answers to questions in report section and not in comment section.

**5. Clean the data set in whichever ways you see fit. This might mean adjusting *variable type*, for example from `character` to `factor`, or dealing with missing data. Assign your cleaned data set to a new data set named `hiphop_clean` -- use this data set going forward.**

```{r}
# code chunk for Q5
# Creates new data set "hiphop_clean" using certain variables from data set "hiphop"
hiphop_clean <- hiphop |>
  select(
    word, subj, sex, age, ethnic, familiarity, trial, fam1, popularityScore, 
    city, county, bieber) |>
  
# Variable "familiarity" is converted to factor
  mutate(
    familarity = as.factor(familiarity))
```

# Data Summaries

**6. How many unique AAE words were studied in this data set?**

```{r}
# code chunk for Q6
# Displays each unique word
hiphop_clean |>
  distinct(word)
```
Q6 Answer:
There are 64 unique AAE words studied in this data set. This is shown in the
64x1 tibble output that displays each unique word.

Q6 Fix: 
Used the distinct function which created a tibble of each unique word instead
of relying on the count function.


**7. Make a new variable that re-categorizes `ethnic` into only two groups, "white" and "non-white", to simplify your data.**

::: callout-tip
Helpful functions: `mutate()`, `if_else()`
:::

```{r}
# code chunk for Q7
# Creates new variable "ethnic_bin" that re-categorizes variable "ethnic" into
# two groups (white and non-white)
hiphop_clean <- hiphop_clean |>
  mutate(ethnic_bin = 
           case_when(ethnic == "white" ~ "white",
                           TRUE ~ "non-white"))
```

Q7 Fix:
Made it so that hiphop_clean created and saved a variable in its own data set
rather than just creating one.


**8. It is fairly common for researchers to collapse ethnic or racial categories similar to what you just did. What are some issues with representing the data in this way?**

One issues with collapsing ethnic or racial categories is that it generalizes all
other minorities into one category. This can be very misleading for data analysis 
because you don't know which minorities are under or over represented.

**9. What are the demographics of the people in this study? Investigate the variables `sex`, `age`, and `ethnic` and summarize your findings in 1-3 complete sentences.**

In regards to sex, there are 117 females and 51 males in this study. Their ages 
span from 16 to 48 years old with a mean of 20.02 years old. There are 5 of 
African descent, 19 of Asian descent, 1 of Biracial descent, 1 of Black descent, 
3 of Hispanic descent, 2 of Indian descent, 1 of Native descent, 1 of unknown 
descent and 135 of White descent. 

::: callout-tip
You'll need to first manipulate your data to have each person represented only once.

Helpful functions: `select()`, `distinct(___, .keep_all = TRUE)`, `count()`, `summary()`
:::

```{r}
# code chunk for Q9
# Creates new data set "new_hiphop" from data set "hiphop_clean" to have each 
# person represented only once
new_hiphop <- hiphop_clean |>
  select(subj, sex, age, ethnic) |>
  distinct(subj, .keep_all = TRUE)

# Finds frequency of males and females
new_hiphop |>
  count(sex)

# Finds frequency of each ethnic group
new_hiphop |>
  count(ethnic)

# Calculates 5 number summary for age
new_hiphop |>
  summarize(age)
```

Q9 Fix - Considered S:
Uses summarize function as suggested instead of summary function.


**10. Make at least two plots to display the demographic information of the subjects in this study.**

::: callout-note
You do not need to discuss these plots, but make sure they are appropriate to the data types and have informative titles and axis labels. Feel free to use the skills you learned in Challenge 2 to enhance your plots!
:::

```{r}
#| message: false
# code chunk for Q10
# Plot 1
ggplot(data = new_hiphop,
       mapping = aes(x = age)) +
  geom_histogram() +
  facet_wrap(~ ethnic) +
  labs(title = "Distribution of Ages by Ethnicity",
       x = "Age (years)",
       y = "Number of Participants") 

# Plot 2
ggplot(data = new_hiphop,
       mapping = aes(x = age)) +
  geom_histogram() +
  facet_wrap(~ sex) +
  labs(title = "Distribution of Ages by Sex",
       x = "Age (years)",
       y = "Number of Participants")

# Plot 3
ggplot(data = new_hiphop,
       mapping = aes(x = sex,
                     fill = ethnic)) +
  geom_bar() +
  labs(title = "Distribution of Ethnicity by Sex",
       x = "Sex",
       y = "Number of Participants")
```

## Familiar words

For each demographic group listed below, determine which word(s) in this study was(were) the most **and** least familiar on average.

::: callout-tip
Helpful functions: `filter()`, `group_by()`, `summarize()`, `slice_max()`, `slice_min()`

Useful variables: `word`, `familiarity`, `sex`, `age`, `ethnic`
:::

**11. People below the age of 20.**

```{r}
# code chunk for Q11
# Determines which word was the most familiar
hiphop_clean |>
  filter(age < 20, 
         familiarity == 5) |>
  count(word, sort = TRUE)
  
# Determines which words was the least familiar
hiphop_clean |>
  filter(age < 20, 
         familiarity == 1) |>
  count(word, sort = TRUE)

```
Q11 Answer:
For people below the age of 20, the word that was most familiar was "off the
hook" which 93 people marked with a familiarity of 5. The word that was the least 
familiar was "catch the vapors" which had 117 people mark it with a familiarity 
of 1.

**12. Non-white women.**

```{r}
# code chunk for Q12
# Determines which words was the most familiar
hiphop_clean |>
  filter(ethnic != "white", 
         sex == "Female",
         familiarity == 5) |>
  count(word, sort = TRUE)

# Determines which words was the least familiar
hiphop_clean |>
  filter(ethnic != "white", 
         sex == "Female",
         familiarity == 1) |>
  count(word, sort = TRUE)

```
Q12 Answer.
For non-white women, the word that was most familiar was "feel me" which had
20 people mark it with a familiarity of 5. The word that was the least familiar 
was a tie with "break someone out", "dukey rope", "plex", and "rollie" which had
26 people mark it with a familiarity of 1.


**13. White men above the age of 30.**

```{r}
# code chunk for Q13
# Determines which words was the most familiar
hiphop_clean |>
  filter(ethnic == "white", 
         sex == "Male",
         age > 30,
         familiarity == 5) |>
  count(word, sort = TRUE)

# Determines which words was the least familiar
hiphop_clean |>
  filter(ethnic == "white", 
         sex == "Male",
         age > 30,
         familiarity == 1) |>
  count(word, sort = TRUE)
```
Q13 Answer:
For white men above the age of 30, the word that was most familiar was "5-0". 
This word had 4 people mark it with a familiarity of 5. The word that was the 
least familiar was a tie with "ay yo trip", "beezy", "break someone out", 
catch the vapors", "crossroads", "crump", "dap", "dollar cab", "domino", "duckets", 
"face gator", "fetti", "finna", "ghostride", "good hair", "grip grain", "guap", 
"humming", "mail", "plex", "rollie", "saditty", "sweatbox", "trill", and "twurk". 
These all had 5 people mark it with a familiarity of 1.


## Study Subjects

A joke among the [Tidy Tuesday](https://www.tidytuesday.com/) community is that Justin Bieber was one of the subjects in this study. Bieber, a white male, from a relatively small town (10,000-60,000 people) in Ontario would have been 17-23 at the time of the study.

**14. Determine which subject you believe is secretly Bieber, justify your answer.**

::: callout-tip
Refer again to the data set description. There is another clue about Bieber's identity.
:::

```{r}
# code chunk for Q14
# http://jdobr.es/blog/compound-inequalities-r/
findbieber <- hiphop_clean |>
  distinct(subj, .keep_all = TRUE)

findbieber |>
  filter(sex == "Male",
         between(age, 17, 23),
         ethnic == "white",
         between(city, 10000, 60000)) |>
  slice_max(bieber)
```
Q14 Answer:
I believe that subject p17 is Justin Bieber. Subject p17 is a 18 year white 
male in a city of 56,377 people and a Bieber score of 5.

Q14 Fix:
Instead of using bieber >= 5, I used slice_max(bieber) as suggested.


# Lab 3 Submission

You will submit **only** your rendered HTML file. Your HTML file is required to have the following specifications in the YAML options (at the top of your document):

-   be self-contained (`self-contained: true`)
-   include your source code (`code-tools: true`)
-   include all your code and output (`echo: true`)
-   include **no** messages from loading in packages or the data
(`messages: false`)

**If any of the options are not included, your Lab 3 or Challenge 3 assignment will receive an "Incomplete" and you will be required to submit a revision.**


# Challenge 3: Group Comparisons & Data Ethics

## Published Comparisons

In the published article ([You Know What It Is: Learning Words through Listening to Hip-Hop](https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0028248&type=printable)), the author presents a series of comparisons about the variables which most explain an individual's familiarity with African American English (AAE).

Let us instead compare the number of artists participants reported liking for each genre. Specifically, you will determine which music genre most differentiates each of the demographic groups provided.

> Which genre had much higher average (mean or median) reported artists in one group than the other.
>
> -   Male versus Female
> -   White versus Non-White

::: callout-tip
You might find it helpful to first create a new data set with only the variables you are interested in! Look at the Music Variables in the data set description along with the demographics of interest.

Helpful functions: `select()`, `group_by()`, `summarize()`, `across()`

Other useful operations in R: `mean()`, `diff()`, `abs()`, `which.max()`
:::

## Study Design Critique -- Data Ethics

Myself, members of the Tidy Tuesday community, and previous 331 students have voiced concerns regarding the design and social context of this study.

You've already read the [data description (link)](http://conservancy.umn.edu/bitstream/handle/11299/116327/5/explanationAAEHiphopChesley.txt) regarding how participants were recruited for participation in this study. **Now**, you need to read additional details regarding aspects of the study in the published paper: [You Know What It Is: Learning Words through Listening to Hip-Hop](https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0028248&type=printable).

> Based on the design of this study and its context (African American English), what are **at least two** concerns you have? Keep in mind this critique aligns with conversations regarding data ethics. Thus, your concerns need to address the racial aspects of the design of this study.

# Challenge 3 Submission

Your challenge should be submitted as a **separate file**, **not** at the bottom of your Lab 3 file. Please submit your rendered HTML file. You can copy and paste this code into a **new** Quarto file. Your Challenge 3 submission should only included code necessary for completing the Challenge, nothing else.

You will submit **only** your rendered HTML file. Your HTML file is required to have the following specifications in the YAML options (at the top of your document):

-   be self-contained (`self-contained: true`)
-   include your source code (`code-tools: true`)
-   include all your code and output (`echo: true`)
-   include **no** messages from loading in packages or the data
(`messages: false`)

**If any of the options are not included, your Lab 3 or Challenge 3 assignment will receive an "Incomplete" and you will be required to submit a revision.**

